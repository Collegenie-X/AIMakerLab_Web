# Python AI í”„ë¡œê·¸ë˜ë° ì™„ë²½ ê°€ì´ë“œ

> **ì¤‘ê³ ë“±í•™ìƒì„ ìœ„í•œ Python & ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ì „ ê³¼ì •**

## ğŸ“š ëª©ì°¨

1. [Python ê¸°ì´ˆ](#python-ê¸°ì´ˆ)
2. [ë°ì´í„° ë¶„ì„](#ë°ì´í„°-ë¶„ì„)
3. [ë¨¸ì‹ ëŸ¬ë‹ ì…ë¬¸](#ë¨¸ì‹ ëŸ¬ë‹-ì…ë¬¸)
4. [ë”¥ëŸ¬ë‹ í”„ë¡œì íŠ¸](#ë”¥ëŸ¬ë‹-í”„ë¡œì íŠ¸)
5. [ì‹¤ì „ AI í”„ë¡œì íŠ¸](#ì‹¤ì „-ai-í”„ë¡œì íŠ¸)

---

## 1. Python ê¸°ì´ˆ

### ì™œ Pythonì¸ê°€?

```mermaid
mindmap
  root((Python))
    ì‰¬ìš´ ë¬¸ë²•
      ì˜ì–´ì²˜ëŸ¼ ì½í˜
      ë“¤ì—¬ì“°ê¸° ê¸°ë°˜
      ì´ˆë³´ì ì¹œí™”ì 
    ê°•ë ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
      TensorFlow
      PyTorch
      Scikit-learn
      OpenCV
    AI í‘œì¤€ ì–¸ì–´
      Google
      Facebook
      Netflix
      ëŒ€í•™ ì—°êµ¬
```

### ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

#### 1. Python ì„¤ì¹˜
```bash
# Windows
https://python.org ì—ì„œ ë‹¤ìš´ë¡œë“œ

# Mac
brew install python3

# ì„¤ì¹˜ í™•ì¸
python --version
# Python 3.11.0 (ì¶œë ¥ ì˜ˆì‹œ)
```

#### 2. VS Code ì„¤ì¹˜ ë° ì„¤ì •
```
1. VS Code ë‹¤ìš´ë¡œë“œ: https://code.visualstudio.com
2. í™•ì¥ í”„ë¡œê·¸ë¨ ì„¤ì¹˜:
   - Python (Microsoft)
   - Pylance (ì½”ë“œ ìë™ì™„ì„±)
   - Jupyter (ë…¸íŠ¸ë¶)
```

### Python ê¸°ë³¸ ë¬¸ë²•

#### ë³€ìˆ˜ì™€ ë°ì´í„° íƒ€ì…
```python
# ë³€ìˆ˜ ì„ ì–¸
name = "ê¹€AI"      # ë¬¸ìì—´ (string)
age = 15          # ì •ìˆ˜ (integer)
height = 165.5    # ì‹¤ìˆ˜ (float)
is_student = True # ë¶ˆë¦¬ì–¸ (boolean)

# ì¶œë ¥
print(f"{name}ë‹˜ì€ {age}ì‚´ì…ë‹ˆë‹¤.")
# ì¶œë ¥: ê¹€AIë‹˜ì€ 15ì‚´ì…ë‹ˆë‹¤.
```

#### ì¡°ê±´ë¬¸
```python
score = 85

if score >= 90:
    print("Aí•™ì ")
elif score >= 80:
    print("Bí•™ì ")  # ì´ê²ƒì´ ì‹¤í–‰ë¨
elif score >= 70:
    print("Cí•™ì ")
else:
    print("Fí•™ì ")
```

#### ë°˜ë³µë¬¸
```python
# for ë£¨í”„
for i in range(5):
    print(f"ë°˜ë³µ {i+1}íšŒ")

# while ë£¨í”„
count = 0
while count < 3:
    print(f"ì¹´ìš´íŠ¸: {count}")
    count += 1
```

#### í•¨ìˆ˜
```python
def calculate_average(scores):
    """ì ìˆ˜ ë¦¬ìŠ¤íŠ¸ì˜ í‰ê· ì„ ê³„ì‚°"""
    total = sum(scores)
    count = len(scores)
    return total / count

# ì‚¬ìš©
my_scores = [85, 90, 95, 88]
avg = calculate_average(my_scores)
print(f"í‰ê· : {avg}")  # í‰ê· : 89.5
```

---

## 2. ë°ì´í„° ë¶„ì„

### Pandas ê¸°ì´ˆ

```python
import pandas as pd

# CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv('students.csv')

# ë°ì´í„° í™•ì¸
print(df.head())  # ì²˜ìŒ 5ì¤„ ì¶œë ¥
print(df.info())  # ë°ì´í„° ì •ë³´
print(df.describe())  # í†µê³„ ìš”ì•½

# ë°ì´í„° í•„í„°ë§
high_scores = df[df['score'] >= 90]
print(high_scores)

# ê·¸ë£¹ë³„ í‰ê· 
avg_by_class = df.groupby('class')['score'].mean()
print(avg_by_class)
```

### ë°ì´í„° ì‹œê°í™”

```python
import matplotlib.pyplot as plt
import seaborn as sns

# ì„  ê·¸ë˜í”„
plt.plot([1, 2, 3, 4], [10, 20, 25, 30])
plt.title('ì‹œê°„ë³„ ì„±ì  í–¥ìƒ')
plt.xlabel('ê°œì›”')
plt.ylabel('ì ìˆ˜')
plt.show()

# ë§‰ëŒ€ ê·¸ë˜í”„
subjects = ['ìˆ˜í•™', 'ì˜ì–´', 'ê³¼í•™']
scores = [85, 90, 88]
plt.bar(subjects, scores)
plt.title('ê³¼ëª©ë³„ ì ìˆ˜')
plt.show()

# íˆíŠ¸ë§µ
data = [[85, 90], [88, 92], [78, 85]]
sns.heatmap(data, annot=True, cmap='YlGnBu')
plt.title('í•™ìƒë³„ ê³¼ëª©ë³„ ì ìˆ˜')
plt.show()
```

---

## 3. ë¨¸ì‹ ëŸ¬ë‹ ì…ë¬¸

### ë¨¸ì‹ ëŸ¬ë‹ì´ë€?

```mermaid
graph LR
    A[ë°ì´í„° ìˆ˜ì§‘] --> B[ë°ì´í„° ì „ì²˜ë¦¬]
    B --> C[ëª¨ë¸ ì„ íƒ]
    C --> D[ëª¨ë¸ í•™ìŠµ]
    D --> E[ëª¨ë¸ í‰ê°€]
    E --> F{ì„±ëŠ¥ OK?}
    F -->|ì•„ë‹ˆì˜¤| C
    F -->|ì˜ˆ| G[ëª¨ë¸ ë°°í¬]
    
    style D fill:#4169e1,color:#fff
    style G fill:#32cd32,color:#fff
```

### í”„ë¡œì íŠ¸ 1: ê½ƒ ë¶„ë¥˜í•˜ê¸° (Iris Dataset)

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# 1. ë°ì´í„° ë¡œë“œ
iris = load_iris()
X = iris.data   # íŠ¹ì§• (ê½ƒì ê¸¸ì´/ë„ˆë¹„ ë“±)
y = iris.target # ë¼ë²¨ (ê½ƒ ì¢…ë¥˜)

# 2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# 4. ì˜ˆì¸¡
y_pred = model.predict(X_test)

# 5. í‰ê°€
accuracy = accuracy_score(y_test, y_pred)
print(f"ì •í™•ë„: {accuracy * 100:.2f}%")
# ì¶œë ¥: ì •í™•ë„: 96.67%

# 6. ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡
new_flower = [[5.1, 3.5, 1.4, 0.2]]
prediction = model.predict(new_flower)
print(f"ì˜ˆì¸¡ëœ ê½ƒ ì¢…ë¥˜: {iris.target_names[prediction[0]]}")
# ì¶œë ¥: ì˜ˆì¸¡ëœ ê½ƒ ì¢…ë¥˜: setosa
```

### ì•Œê³ ë¦¬ì¦˜ ë¹„êµ

| ì•Œê³ ë¦¬ì¦˜ | ì¥ì  | ë‹¨ì  | ì í•©í•œ ë¬¸ì œ |
|---------|------|------|-----------|
| **Decision Tree** | í•´ì„ ì‰¬ì›€ | ê³¼ì í•© ìœ„í—˜ | ë¶„ë¥˜, íšŒê·€ |
| **Random Forest** | ì •í™•ë„ ë†’ìŒ | í•™ìŠµ ëŠë¦¼ | ë³µì¡í•œ ë¶„ë¥˜ |
| **SVM** | ì†ŒëŸ‰ ë°ì´í„°ì— ê°•í•¨ | ëŒ€ëŸ‰ ë°ì´í„° ëŠë¦¼ | ì´ë¯¸ì§€ ë¶„ë¥˜ |
| **K-NN** | êµ¬í˜„ ê°„ë‹¨ | ì˜ˆì¸¡ ëŠë¦¼ | ì¶”ì²œ ì‹œìŠ¤í…œ |

---

## 4. ë”¥ëŸ¬ë‹ í”„ë¡œì íŠ¸

### TensorFlow/Keras ê¸°ì´ˆ

```python
import tensorflow as tf
from tensorflow import keras

# 1. ë°ì´í„° ë¡œë“œ (ì†ê¸€ì”¨ ìˆ«ì)
(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()

# 2. ë°ì´í„° ì „ì²˜ë¦¬
X_train = X_train / 255.0  # 0-1 ì‚¬ì´ë¡œ ì •ê·œí™”
X_test = X_test / 255.0

# 3. ëª¨ë¸ êµ¬ì¡° ì •ì˜
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),  # ì…ë ¥ì¸µ
    keras.layers.Dense(128, activation='relu'),   # ì€ë‹‰ì¸µ
    keras.layers.Dropout(0.2),                    # ë“œë¡­ì•„ì›ƒ
    keras.layers.Dense(10, activation='softmax')  # ì¶œë ¥ì¸µ
])

# 4. ëª¨ë¸ ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# 5. ëª¨ë¸ í•™ìŠµ
history = model.fit(
    X_train, y_train,
    epochs=5,
    validation_split=0.2,
    batch_size=32
)

# 6. ëª¨ë¸ í‰ê°€
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc * 100:.2f}%")
# ì¶œë ¥: í…ŒìŠ¤íŠ¸ ì •í™•ë„: 97.85%

# 7. ì˜ˆì¸¡
import numpy as np
predictions = model.predict(X_test[:5])
for i, pred in enumerate(predictions):
    predicted_digit = np.argmax(pred)
    actual_digit = y_test[i]
    print(f"ì˜ˆì¸¡: {predicted_digit}, ì‹¤ì œ: {actual_digit}")
```

### í•™ìŠµ ê³¼ì • ì‹œê°í™”

```python
import matplotlib.pyplot as plt

# ì •í™•ë„ ê·¸ë˜í”„
plt.plot(history.history['accuracy'], label='í•™ìŠµ ì •í™•ë„')
plt.plot(history.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„')
plt.xlabel('Epoch')
plt.ylabel('ì •í™•ë„')
plt.legend()
plt.show()

# ì†ì‹¤ ê·¸ë˜í”„
plt.plot(history.history['loss'], label='í•™ìŠµ ì†ì‹¤')
plt.plot(history.history['val_loss'], label='ê²€ì¦ ì†ì‹¤')
plt.xlabel('Epoch')
plt.ylabel('ì†ì‹¤')
plt.legend()
plt.show()
```

---

## 5. ì‹¤ì „ AI í”„ë¡œì íŠ¸

### í”„ë¡œì íŠ¸ 1: ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°

#### ëª©í‘œ
ì›¹ìº ìœ¼ë¡œ ì°ì€ ì‚¬ì§„ì„ ë³´ê³  ê°œ/ê³ ì–‘ì´ ë¶„ë¥˜

#### ë‹¨ê³„ë³„ êµ¬í˜„

**1. ë°ì´í„°ì…‹ ì¤€ë¹„**
```python
# Kaggleì—ì„œ Dogs vs Cats ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
# í´ë” êµ¬ì¡°:
# dataset/
#   train/
#     dogs/
#       dog.0.jpg
#       dog.1.jpg
#       ...
#     cats/
#       cat.0.jpg
#       cat.1.jpg
#       ...
```

**2. ë°ì´í„° ì¦ê°•**
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    'dataset/train',
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    'dataset/train',
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)
```

**3. CNN ëª¨ë¸ êµ¬ì¶•**
```python
from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
```

**4. í•™ìŠµ**
```python
history = model.fit(
    train_generator,
    epochs=25,
    validation_data=validation_generator
)

# ëª¨ë¸ ì €ì¥
model.save('dog_cat_classifier.h5')
```

**5. ì‹¤ì‹œê°„ ì˜ˆì¸¡**
```python
import cv2
import numpy as np

# ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    img = cv2.resize(frame, (150, 150))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    
    # ì˜ˆì¸¡
    prediction = model.predict(img)[0][0]
    
    # ê²°ê³¼ í‘œì‹œ
    if prediction > 0.5:
        label = f"ê°œ ({prediction*100:.1f}%)"
        color = (0, 255, 0)
    else:
        label = f"ê³ ì–‘ì´ ({(1-prediction)*100:.1f}%)"
        color = (255, 0, 0)
    
    cv2.putText(frame, label, (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    cv2.imshow('Dog vs Cat Classifier', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

### í”„ë¡œì íŠ¸ 2: ì±—ë´‡ ë§Œë“¤ê¸°

#### ëª©í‘œ
ê°„ë‹¨í•œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” AI ì±—ë´‡

#### êµ¬í˜„
```python
from transformers import pipeline

# GPT-2 ê¸°ë°˜ ì±—ë´‡
chatbot = pipeline('text-generation', model='gpt2')

def chat(user_input):
    response = chatbot(user_input, max_length=50, num_return_sequences=1)
    return response[0]['generated_text']

# ì‚¬ìš©
while True:
    user_input = input("You: ")
    if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
        break
    
    bot_response = chat(user_input)
    print(f"Bot: {bot_response}")
```

---

## ë¶€ë¡: í•™ìŠµ ìë£Œ

### ì¶”ì²œ ë¼ì´ë¸ŒëŸ¬ë¦¬

```mermaid
graph TB
    subgraph "ë°ì´í„° ì²˜ë¦¬"
        A1[NumPy<br/>ìˆ˜ì¹˜ ê³„ì‚°]
        A2[Pandas<br/>ë°ì´í„° ë¶„ì„]
    end
    
    subgraph "ì‹œê°í™”"
        B1[Matplotlib<br/>ê¸°ë³¸ ê·¸ë˜í”„]
        B2[Seaborn<br/>í†µê³„ ì‹œê°í™”]
    end
    
    subgraph "ë¨¸ì‹ ëŸ¬ë‹"
        C1[Scikit-learn<br/>ì „í†µì  ML]
        C2[TensorFlow<br/>ë”¥ëŸ¬ë‹]
        C3[PyTorch<br/>ì—°êµ¬ìš© DL]
    end
    
    subgraph "ì»´í“¨í„° ë¹„ì „"
        D1[OpenCV<br/>ì´ë¯¸ì§€ ì²˜ë¦¬]
        D2[PIL<br/>ì´ë¯¸ì§€ ì¡°ì‘]
    end
    
    style C2 fill:#ff6f00,color:#fff
    style C3 fill:#ee4c2c,color:#fff
```

### í•™ìŠµ ë¡œë“œë§µ (6ê°œì›”)

```mermaid
gantt
    title Python AI 6ê°œì›” ë§ˆìŠ¤í„° í”Œëœ
    dateFormat YYYY-MM-DD
    
    section Python ê¸°ì´ˆ (1ê°œì›”)
    ë¬¸ë²• ê¸°ì´ˆ                :a1, 2025-01-01, 15d
    ìë£Œêµ¬ì¡°, í•¨ìˆ˜            :a2, after a1, 15d
    
    section ë°ì´í„° ë¶„ì„ (1ê°œì›”)
    Pandas, NumPy           :b1, after a2, 15d
    Matplotlib ì‹œê°í™”        :b2, after b1, 15d
    
    section ë¨¸ì‹ ëŸ¬ë‹ (2ê°œì›”)
    Scikit-learn ê¸°ì´ˆ        :c1, after b2, 20d
    íšŒê·€, ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜       :c2, after c1, 20d
    í”„ë¡œì íŠ¸ 1               :c3, after c2, 20d
    
    section ë”¥ëŸ¬ë‹ (2ê°œì›”)
    TensorFlow ê¸°ì´ˆ          :d1, after c3, 20d
    CNN, RNN êµ¬ì¡°            :d2, after d1, 20d
    í”„ë¡œì íŠ¸ 2               :d3, after d2, 20d
```

---

**Pythonìœ¼ë¡œ AIì˜ ì„¸ê³„ë¥¼ íƒí—˜í•˜ì„¸ìš”!** ğŸğŸ¤–

AI Maker Labê³¼ í•¨ê»˜ë¼ë©´ ëˆ„êµ¬ë‚˜ AI ê°œë°œìê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

