# 로봇팔 + 컴퓨터 비전 융합 교육 커리큘럼

## 📚 목차
1. [교육 개요](#교육-개요)
2. [시스템 아키텍처](#시스템-아키텍처)
3. [입출력 시스템 분석](#입출력-시스템-분석)
4. [ESP32 버전 커리큘럼](#esp32-버전-커리큘럼)
5. [라즈베리파이 버전 커리큘럼](#라즈베리파이-버전-커리큘럼)
6. [프로젝트 기반 학습](#프로젝트-기반-학습)
7. [가상 시뮬레이션 → 실제 적용](#가상-시뮬레이션--실제-적용)

---

## 🎯 교육 개요

### 교육 철학: 가상 → 실제 → 최적화

> **[간단한 흐름도]** 본문에서 단계별로 설명합니다.

### 학습 목표

**기술적 목표:**
- 센서(입력)와 액추에이터(출력)의 명확한 이해
- 컴퓨터 비전을 통한 객체 인식 및 위치 파악
- 역기구학(Inverse Kinematics) 알고리즘 이해
- 센서 데이터 → 의사결정 → 동작 제어 프로세스 설계

**융합적 사고력:**
- 물리학: 로봇팔의 각도와 토크
- 수학: 삼각함수, 벡터, 좌표 변환
- 컴퓨터 과학: 알고리즘, 데이터 구조, 영상 처리
- 공학: 시스템 설계, 제어 이론

---

## 🏗️ 시스템 아키텍처

### 전체 시스템 구조

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

### 로봇팔 기구학 구조

> **[간단한 흐름도]** 본문에서 단계별로 설명합니다.

---

## 🔌 입출력 시스템 분석

### 입력(센서) 시스템

| 센서 종류 | 측정 데이터 | 데이터 타입 | 용도 | 통신 방식 |
|---------|-----------|-----------|-----|---------|
| **카메라** | 영상 (640x480 픽셀) | 이미지 배열 | 객체 인식, 위치 파악 | USB/CSI |
| **초음파 거리 센서** | 거리 (2-400cm) | 정수 (cm) | 장애물 회피, 거리 측정 | GPIO (Trigger/Echo) |
| **컬러 센서** | RGB 값 (0-255) | 정수 3개 | 색상 분류, 물체 구별 | I2C |
| **압력 센서** | 압력 (0-1023) | 아날로그 값 | 그립 힘 조절, 물체 감지 | ADC |
| **자이로/가속도계** | 각속도, 가속도 | 부동소수점 6개 | 로봇팔 기울기, 안정성 | I2C/SPI |

### 출력(액추에이터) 시스템

| 액추에이터 | 제어 신호 | 제어 범위 | 물리적 동작 | 통신 방식 |
|----------|---------|---------|-----------|---------|
| **서보 모터 1 (베이스)** | PWM 신호 | 0-180도 | 좌우 회전 | PWM (50Hz) |
| **서보 모터 2 (어깨)** | PWM 신호 | 0-180도 | 상하 움직임 | PWM (50Hz) |
| **서보 모터 3 (팔꿈치)** | PWM 신호 | 0-180도 | 팔 펼침/접힘 | PWM (50Hz) |
| **서보 모터 4 (그리퍼)** | PWM 신호 | 0-90도 | 물체 파지/해제 | PWM (50Hz) |
| **LED 피드백** | 디지털 신호 | ON/OFF | 상태 표시 | GPIO |
| **부저** | PWM 주파수 | 20Hz-20kHz | 소리 알림 | PWM |

### 데이터 흐름 다이어그램

> **[시퀀스 다이어그램 생략]** 동작 순서는 본문을 참조하세요.

---

## 🤖 ESP32 버전 커리큘럼 (총 20시간)

### ESP32의 장점과 한계

**장점:**
- ✅ 저가 (약 8,000원)
- ✅ WiFi/Bluetooth 내장 → 무선 제어 가능
- ✅ 듀얼 코어 → 센서 읽기와 모터 제어 병렬 처리
- ✅ 저전력 → 배터리 구동 가능

**한계:**
- ❌ 카메라 처리 능력 제한 (ESP32-CAM: 저해상도만 가능)
- ❌ AI 모델 실행 어려움 (TinyML로 간단한 모델만)
- ❌ 복잡한 영상 처리 불가

**해결책:**
- 컴퓨터 비전은 **PC나 스마트폰에서 처리**
- ESP32는 센서 데이터 수집 + 모터 제어에만 집중
- WiFi로 PC/스마트폰과 통신

---

### 1단계: 가상 시뮬레이션 (2시간)

#### 학습 목표
- 로봇팔의 동작 원리 이해
- 좌표계와 각도의 관계 파악
- 시뮬레이터로 안전하게 실험

#### 순서도: 시뮬레이터 사용 흐름

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 사용 도구
- **PC 시뮬레이터**: 
  - [Robot Arm Simulator (Web)](https://github.com/RobotLocomotion/drake)
  - Tinkercad Circuits (온라인, 무료)
- **앱**: 
  - Robot Arm Controller (Android/iOS)

#### 실습 활동

**활동 1: 순기구학 이해**
```
입력: 각 관절 각도 (θ1, θ2, θ3)
출력: 로봇팔 끝단 위치 (x, y, z)

예시:
  θ1 = 90도 (베이스 정면)
  θ2 = 45도 (어깨 45도)
  θ3 = 30도 (팔꿈치 30도)
  
  → 끝단 위치: (x=15cm, y=0cm, z=12cm)
```

**활동 2: 역기구학 이해**
```
입력: 목표 위치 (x, y, z)
출력: 필요한 관절 각도 (θ1, θ2, θ3)

예시:
  목표: (x=10cm, y=5cm, z=8cm)
  
  → 베이스 각도: θ1 = arctan(y/x) = 26.6도
  → 어깨 각도: θ2 = (역기구학 계산)
  → 팔꿈치 각도: θ3 = (역기구학 계산)
```

---

### 2단계: 하드웨어 구성 및 센서 테스트 (4시간)

#### 필요 부품 목록

| 부품 | 수량 | 용도 | 예상 가격 |
|-----|-----|-----|---------|
| ESP32 DevKit | 1 | 메인 컨트롤러 | 8,000원 |
| SG90 서보 모터 | 4 | 로봇팔 관절 | 24,000원 (6,000원x4) |
| HC-SR04 초음파 센서 | 1 | 거리 측정 | 3,000원 |
| TCS34725 컬러 센서 | 1 | 색상 인식 | 8,000원 |
| FSR 압력 센서 | 1 | 그립 힘 측정 | 3,000원 |
| 5V 3A 전원 어댑터 | 1 | 서보 모터 전원 | 8,000원 |
| 브레드보드, 점퍼선 | 1세트 | 회로 구성 | 5,000원 |
| **합계** | | | **약 59,000원** |

#### 회로 연결 다이어그램

```
// ... [코드 생략] ...
```

#### 알고리즘: 센서 캘리브레이션

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 실습 활동

**활동 1: 서보 모터 단독 테스트**
```
// ... [코드 생략] ...
```

**활동 2: 거리 센서 측정**
```
// ... [코드 생략] ...
```

**활동 3: 컬러 센서 색상 인식**
```
// ... [코드 생략] ...
```

---

### 3단계: 로봇팔 제어 알고리즘 (6시간)

#### 알고리즘 1: 역기구학 (Inverse Kinematics)

**문제 정의:**
- 입력: 목표 위치 (x, y, z)
- 출력: 각 관절 각도 (θ1, θ2, θ3)

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

**수학 공식:**

```
// ... [코드 생략] ...
```

#### 알고리즘 2: 경로 계획 (Path Planning)

**문제 정의:**
- 입력: 시작 위치 (x1, y1, z1), 목표 위치 (x2, y2, z2)
- 출력: 중간 경로점들의 시퀀스

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

**선형 보간 알고리즘:**

```
// ... [코드 생략] ...
```

#### 알고리즘 3: 충돌 감지 및 안전 제어

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

---

### 4단계: WiFi 통신 및 원격 제어 (4시간)

#### 시스템 구조: ESP32 ↔ PC/스마트폰

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 알고리즘: 명령 프로토콜

**JSON 기반 통신 프로토콜:**

```
// ... [코드 생략] ...
```

#### 순서도: 명령 처리

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 실습 활동

**활동: Python으로 ESP32 제어하기**

```
// ... [코드 생략] ...
```

---

### 5단계: PC 컴퓨터 비전 통합 (4시간)

#### 시스템 구조

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 알고리즘: 색상 기반 객체 인식

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

**세부 알고리즘:**

```
// ... [코드 생략] ...
```

#### 카메라 캘리브레이션

```
// ... [코드 생략] ...
```

#### 실습 활동

**활동 1: 색상별 물체 분류**

```
// ... [코드 생략] ...
```

**활동 2: 형태 인식 (동그라미 vs 네모)**

```
// ... [코드 생략] ...
```

---

## 🍓 라즈베리파이 버전 커리큘럼 (총 24시간)

### 라즈베리파이의 장점

**ESP32와의 차이점:**
- ✅ 강력한 CPU → 실시간 컴퓨터 비전 처리 가능
- ✅ 라즈베리파이 카메라 모듈 → 고해상도 영상
- ✅ Python → OpenCV, TensorFlow 완벽 지원
- ✅ Linux 기반 → SSH, 네트워크, 파일 시스템
- ✅ AI 모델 실행 가능 → TensorFlow Lite, YOLO

**단점:**
- ❌ 가격이 비쌈 (약 7만원 + 카메라 3만원 = 10만원)
- ❌ 전력 소비 큼 (배터리 구동 어려움)
- ❌ 실시간 제어에는 Arduino/ESP32보다 약함

**최적 구성:**
- 라즈베리파이: 카메라 + AI + 의사결정
- ESP32/Arduino: 실시간 모터 제어

---

### 1단계: 라즈베리파이 + 카메라 설정 (2시간)

#### 하드웨어 구성

```
라즈베리파이 4B (4GB)
  ├─ 카메라 모듈 V2 (CSI 케이블 연결)
  ├─ GPIO → ESP32 (UART 통신)
  ├─ USB → 웹캠 (대안)
  └─ HDMI → 모니터 (초기 설정용)
```

#### 소프트웨어 설치 순서도

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 카메라 테스트 알고리즘

```
// ... [코드 생략] ...
```

---

### 2단계: OpenCV 기초 - 실시간 객체 인식 (4시간)

#### 알고리즘 1: ArUco 마커 인식

**ArUco 마커란?**
- 로봇 비전에서 많이 사용하는 2D 바코드
- 정확한 위치와 방향(pose) 계산 가능
- 인쇄하여 물체에 부착

> **[간단한 흐름도]** 본문에서 단계별로 설명합니다.

**세부 알고리즘:**

```
// ... [코드 생략] ...
```

#### 알고리즘 2: 실시간 얼굴 감지 (OpenCV Haar Cascade)

```
// ... [코드 생략] ...
```

---

### 3단계: TensorFlow Lite 객체 인식 (6시간)

#### AI 모델 기반 객체 인식

**ESP32와의 차별점:**
- ESP32: 색상, 마커 등 단순한 특징만 인식
- 라즈베리파이: 딥러닝 모델로 복잡한 객체 인식 가능

> **[간단한 흐름도]** 본문에서 단계별로 설명합니다.

#### 알고리즘: TensorFlow Lite 객체 감지

```
// ... [코드 생략] ...
```

#### 커스텀 모델 학습 (심화)

```
// ... [코드 생략] ...
```

---

### 4단계: 라즈베리파이 ↔ ESP32 통신 (4시간)

#### 시스템 아키텍처

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 통신 프로토콜

**명령 형식 (라즈베리파이 → ESP32):**

```
// ... [코드 생략] ...
```

#### 알고리즘: 직렬 통신 (라즈베리파이 측)

```
// ... [코드 생략] ...
```

#### 알고리즘: 직렬 통신 (ESP32 측)

```
// ... [코드 생략] ...
```

---

### 5단계: 통합 프로젝트 - 자율 물체 정렬 시스템 (8시간)

#### 프로젝트 목표

**시나리오:**
탁자 위에 다양한 물체(컵, 병, 과일 등)가 무작위로 놓여있음
로봇팔이 카메라로 물체를 인식하고, 종류별로 정렬하여 지정된 위치에 배치

> **[프로세스 다이어그램 생략]** 단계별 설명은 본문을 참조하세요.

#### 메인 알고리즘

```
// ... [코드 생략] ...
```

---

## 📊 평가 및 성찰

### 프로젝트 평가 기준

> **[마인드맵 다이어그램 생략]** 주요 개념은 본문에서 설명합니다.

### 학생 자기 평가 질문

1. **입력과 출력의 이해**
   - 사용한 센서(입력)는 무엇이며, 각각 어떤 데이터를 제공하나요?
   - 사용한 액추에이터(출력)는 무엇이며, 어떤 제어 신호가 필요한가요?

2. **알고리즘 설계**
   - 역기구학 알고리즘을 순서도로 그려보세요
   - 물체 인식 알고리즘의 핵심 단계 3가지는 무엇인가요?

3. **문제 해결**
   - 프로젝트 중 가장 어려웠던 문제는 무엇이었나요?
   - 어떻게 해결했나요? (시행착오 포함)

4. **융합적 사고**
   - 이 프로젝트에 어떤 과목의 지식이 사용되었나요?
   - 실생활에서 비슷한 기술이 어디에 활용되나요?

---

## 📈 확장 프로젝트 아이디어

### 프로젝트 1: 자동 체스 플레이어
- 카메라로 체스판 인식
- AI가 다음 수 계산
- 로봇팔이 말을 이동

### 프로젝트 2: 재활용 분류 로봇
- 컬러 센서 + AI로 재질 구분
- 플라스틱/유리/종이 자동 분류
- 환경 보호 메시지

### 프로젝트 3: 자동 약 분배기
- 시간에 맞춰 약 제공
- 얼굴 인식으로 사용자 확인
- 복용 기록 저장

### 프로젝트 4: 그림 그리는 로봇
- 이미지를 윤곽선으로 변환
- 로봇팔이 펜을 잡고 그림
- 예술과 기술의 융합

---

## 📚 참고 자료

### 온라인 시뮬레이터
- Tinkercad Circuits: https://www.tinkercad.com
- Robot Arm Simulator: https://robot-arm-simulator.com

### OpenCV 튜토리얼
- 공식 문서: https://docs.opencv.org
- PyImageSearch: https://www.pyimagesearch.com

### TensorFlow Lite
- 공식 가이드: https://www.tensorflow.org/lite
- 사전 학습 모델: https://www.tensorflow.org/lite/models

### 로봇 공학 이론
- Introduction to Robotics (Stanford)
- Modern Robotics (Northwestern)

---

## 📝 문서 정보

**작성자**: AI Maker Lab 교육팀  
**최종 업데이트**: 2025-01-06  
**문서 버전**: 1.0  
**대상**: 중고등학생, 교사, 교육 기획자

**특징**:
- ✅ 코드 없이 알고리즘과 순서도 중심
- ✅ 입력/출력 시스템 명확히 구분
- ✅ 가상 시뮬레이션 → 실제 구현 단계적 접근
- ✅ ESP32와 라즈베리파이 두 버전 제공
- ✅ 컴퓨터 비전 + 로봇 제어 융합

**피드백**: 
이 커리큘럼을 사용하면서 개선점이나 추가 아이디어가 있으면 공유해주세요!

